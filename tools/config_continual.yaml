version: v1.0.0
random_seed: 133
port: 11111

# Continual Learning Configuration
continual_learning:
  # Task order - order in which classes are learned
  class_order:
    - bottle
    - cable
    - capsule
    - carpet
    - grid
    - hazelnut
    - leather
    - metal_nut
    - pill
    - screw
    - tile
    - toothbrush
    - transistor
    - wood
    - zipper

  # Number of classes per task (can be int or list)
  # If int: same number of classes for all tasks
  # If list: specific number for each task
  classes_per_task: 1  # 1 class per task = 15 tasks total

  # Training epochs per task
  epochs_per_task: 1

  # Learning rate schedule
  min_lr: 1.0e-08

# Dataset Configuration
dataset:
  type: custom
  image_reader:
    type: opencv
    kwargs:
      image_dir: ./data/MVTec-AD/mvtec_anomaly_detection
      color_mode: RGB
  train:
    meta_file: ./data/MVTec-AD/train.json
    rebalance: false
    hflip: false
    vflip: false
    rotate: false
  test:
    meta_file: ./data/MVTec-AD/test.json
  input_size:
    - 224
    - 224
  pixel_mean:
    - 0.485
    - 0.456
    - 0.406
  pixel_std:
    - 0.229
    - 0.224
    - 0.225
  batch_size: 8
  workers: 4

# Loss Configuration
criterion:
  - name: FeatureMSELoss
    type: FeatureMSELoss
    kwargs:
      weight: 1.0

# Trainer Configuration
trainer:
  max_epoch: 100  # This will be overridden by continual_learning.epochs_per_task
  clip_max_norm: 0.1
  val_freq_epoch: 10
  print_freq_step: 100
  tb_freq_step: 1
  lr_scheduler:
    type: CosineAnnealingLR
    kwargs:
      T_max: 100  # Should match epochs_per_task
      eta_min: 1.0e-08
  optimizer:
    type: AdamW
    kwargs:
      lr: 0.0001
      betas:
        - 0.9
        - 0.999
      weight_decay: 0.0001

# Saver Configuration
saver:
  auto_resume: false
  always_save: false
  load_path: null
  save_dir: checkpoints_cl/
  log_dir: logs_cl/

# Evaluator Configuration
evaluator:
  save_dir: result_eval_cl
  key_metric: mean_pixel_auc
  metrics:
    auc:
      - name: std
      - name: max
        kwargs:
          avgpool_size:
            - 16
            - 16
      - name: pixel
  vis_compound:
    save_dir: ./tools/vis_compound_cl
    max_score: null
    min_score: null

# Frozen layers (not trained during CL)
frozen_layers:
  - backbone

# Network Architecture
net:
  - name: backbone
    type: models.backbones.efficientnet_b4
    frozen: true
    kwargs:
      pretrained: true
      outlayers:
        - 1
        - 2
        - 3
        - 4
      outstrides:
        - 4
        - 8
        - 16
        - 32
  - name: neck
    prev: backbone
    type: models.necks.MFCN
    kwargs:
      outplanes:
        - 120
      outstrides:
        - 16
  - name: reconstruction
    prev: neck
    type: models.reconstructions.UniADMemory
    kwargs:
      pos_embed_type: learned
      hidden_dim: 256
      nhead: 8
      num_encoder_layers: 4
      num_decoder_layers: 4
      dim_feedforward: 1024
      feature_size:
        - 14
        - 14
      dropout: 0.1
      activation: relu
      normalize_before: false
      memory_size: 256
      feature_jitter:
        scale: 20.0
        prob: 1.0
      save_recon:
        save_dir: result_recon_cl
      initializer:
        method: xavier_uniform

# WandB Configuration (optional)
wandb:
  enabled: false
  project: UniAD-MVTec-CL
  entity: null
  name: continual_learning_baseline
  tags:
    - continual-learning
    - anomaly-detection
    - mvtec
    - baseline
  notes: Continual Learning baseline for UniAD on MVTec-AD without replay
  mode: online
  group: null
  job_type: continual_train
  resume: allow
  run_id: null
  dir: null
  login: false
  api_key: null
