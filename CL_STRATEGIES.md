# ğŸ¯ Continual Learning Strategies cho AnoCL

## ğŸ“Š Tá»•ng quan 4 Strategies

| Strategy | SEMA Adapters | Memory | Freeze Strategy | Config File |
|----------|--------------|--------|-----------------|-------------|
| **1. Baseline** | âŒ No | Single (retrain) | Backbone only | `config_continual.yaml` |
| **2. SEMA** | âœ… Yes | Single (retrain) | Backbone + old adapters | `config_sema.yaml` |
| **3. MemExpand** | âŒ No | **Stack memories** | Backbone + old modules | `config_mem_expand.yaml` |
| **4. SEMA+Mem** | âœ… Yes | **Stack memories** | Backbone + all old | `config_sema_mem.yaml` |

---

## ğŸ” Chi tiáº¿t tá»«ng Strategy

### **1ï¸âƒ£ Baseline (No CL Strategy)**

```yaml
cl_strategy: baseline
```

**CÆ¡ cháº¿:**
- Freeze: **Chá»‰ backbone**
- Train: Neck + Memory + Transformer má»—i task
- KhÃ´ng cÃ³ anti-forgetting mechanism

**Timeline:**
```
Task 0:
  Backbone:      â„ï¸ FROZEN
  Neck:          âœ… Train
  Memory:        âœ… Train
  Transformer:   âœ… Train

Task 1:
  Backbone:      â„ï¸ FROZEN
  Neck:          âœ… Retrain (overwrite T0 weights)
  Memory:        âœ… Retrain (overwrite T0 weights)
  Transformer:   âœ… Retrain (overwrite T0 weights)
  â†’ CATASTROPHIC FORGETTING!
```

**Pros:**
- âœ… Simple, khÃ´ng cáº§n extra memory
- âœ… Fast training

**Cons:**
- âŒ **High forgetting** (~0.20)
- âŒ KhÃ´ng cÃ³ CL mechanism

---

### **2ï¸âƒ£ SEMA (Adapters Only)**

```yaml
cl_strategy: sema

sema:
  use_sema: true
  expansion_threshold: 3.0
```

**CÆ¡ cháº¿:**
- Freeze: Backbone + **old SEMA adapters**
- Train: Neck + Memory + Transformer + **new adapters**
- Self-expansion khi detect distribution shift

**Timeline:**
```
Task 0:
  Backbone:      â„ï¸ FROZEN
  Neck:          âœ… Train
  Memory:        âœ… Train
  Transformer:   âœ… Train
  Adapters:      âœ… Train (8 adapters init, 1 per layer)

After Task 0:
  Adapters_T0:   ğŸ”’ FREEZE

Task 1:
  Backbone:      â„ï¸ FROZEN
  Neck:          âœ… Retrain
  Memory:        âœ… Retrain
  Transformer:   âœ… Retrain
  Adapters_T0:   ğŸ”’ FROZEN
  Adapters_T1:   âœ… Train (new adapters if Z-score > threshold)
```

**Pros:**
- âœ… **Lower forgetting** (~0.15) than baseline
- âœ… Self-expansion (automatic)
- âœ… Moderate memory increase

**Cons:**
- âŒ Váº«n cÃ³ forgetting á»Ÿ neck/memory/transformer
- âŒ ThÃªm ~2-4M params (adapters)

---

### **3ï¸âƒ£ MemExpand (Memory Stacking)**

```yaml
cl_strategy: mem_expand
```

**CÆ¡ cháº¿:**
- Freeze: Backbone + **old neck + old memory + old transformer**
- Train: **New neck + new memory + new transformer** (fresh modules)
- Stack outputs tá»« táº¥t cáº£ modules

**Timeline:**
```
Task 0:
  Backbone:          â„ï¸ FROZEN
  Neck_T0:           âœ… Train
  Memory_T0:         âœ… Train
  Transformer_T0:    âœ… Train

After Task 0:
  Neck_T0:           ğŸ”’ FREEZE + Save
  Memory_T0:         ğŸ”’ FREEZE + Save
  Transformer_T0:    ğŸ”’ FREEZE + Save

Task 1:
  Backbone:          â„ï¸ FROZEN
  
  # Frozen modules from T0
  Neck_T0:           ğŸ”’ FROZEN
  Memory_T0:         ğŸ”’ FROZEN
  Transformer_T0:    ğŸ”’ FROZEN
  
  # New modules for T1
  Neck_T1:           âœ… Train (new instance)
  Memory_T1:         âœ… Train (new instance)
  Transformer_T1:    âœ… Train (new instance)

Inference:
  pred = average(T0_output, T1_output)
```

**Pros:**
- âœ… **Zero forgetting** (old modules frozen)
- âœ… KhÃ´ng cáº§n SEMA complexity

**Cons:**
- âŒ **Linear memory growth** (~11M per task)
- âŒ Slower inference (forward through all modules)

---

### **4ï¸âƒ£ SEMA + MemExpand (Combined)**

```yaml
cl_strategy: sema_mem_expand

sema:
  use_sema: true
  expansion_threshold: 3.0
```

**CÆ¡ cháº¿:**
- Freeze: Backbone + **old everything** (modules + adapters)
- Train: New modules + new adapters
- Best of both worlds

**Timeline:**
```
Task 0:
  Backbone:          â„ï¸ FROZEN
  Neck_T0:           âœ… Train
  Memory_T0:         âœ… Train
  Transformer_T0:    âœ… Train
  Adapters_T0:       âœ… Train (8 init)

After Task 0:
  Everything_T0:     ğŸ”’ FREEZE + Save

Task 1:
  Backbone:          â„ï¸ FROZEN
  Everything_T0:     ğŸ”’ FROZEN
  
  # New modules
  Neck_T1:           âœ… Train
  Memory_T1:         âœ… Train
  Transformer_T1:    âœ… Train
  Adapters_T1:       âœ… Train (+ expansion if needed)

Inference:
  pred = mix(T0_output, T1_output)
```

**Pros:**
- âœ… **Lowest forgetting** (everything frozen)
- âœ… Self-expansion adapters
- âœ… Flexible adaptation

**Cons:**
- âŒ **Highest memory** (~13M per task)
- âŒ Most complex

---

## ğŸš€ CÃ¡ch cháº¡y

### **Strategy 1: Baseline**
```bash
python train_continual.py --config config_continual.yaml
```

### **Strategy 2: SEMA**
```bash
python train_continual.py --config config_sema.yaml
```

### **Strategy 3: MemExpand**
```bash
python train_continual.py --config config_mem_expand.yaml
```

### **Strategy 4: SEMA + MemExpand**
```bash
python train_continual.py --config config_sema_mem.yaml
```

---

## ğŸ“Š So sÃ¡nh Performance (Dá»± Ä‘oÃ¡n)

| Strategy | Avg Perf (Final) | Avg Forgetting (Final) | Memory Growth | Speed |
|----------|-----------------|----------------------|---------------|-------|
| **Baseline** | 0.74 | **0.20** âŒ | 0 MB | âš¡âš¡âš¡ Fast |
| **SEMA** | 0.78 | **0.15** ğŸŸ¡ | +2-4 MB | âš¡âš¡ Medium |
| **MemExpand** | **0.82** | **0.05** âœ… | +165 MB (15 tasks) | âš¡ Slow |
| **SEMA+Mem** | **0.85** | **0.02** âœ…âœ… | +195 MB (15 tasks) | âš¡ Slow |

**TÃ­nh toÃ¡n memory:**
- MemExpand: ~11M params/task Ã— 15 tasks = 165M params â‰ˆ 660 MB
- SEMA+Mem: ~13M params/task Ã— 15 tasks = 195M params â‰ˆ 780 MB

---

## ğŸ’¡ Khi nÃ o dÃ¹ng Strategy nÃ o?

### **Baseline** - Debug/Research
- Chá»‰ Ä‘á»ƒ baseline comparison
- KhÃ´ng recommend cho production

### **SEMA** - Balanced
- **Recommended** cho háº§u háº¿t use cases
- Balance giá»¯a performance vÃ  memory
- Tá»‘t khi cÃ³ 5-15 tasks

### **MemExpand** - High Performance
- Khi cáº§n **zero forgetting**
- CÃ³ Ä‘á»§ memory budget
- Sá»‘ tasks Ã­t (< 10)

### **SEMA + MemExpand** - Best Performance
- Khi cáº§n **best possible results**
- Memory khÃ´ng pháº£i váº¥n Ä‘á»
- Production systems vá»›i high accuracy requirements

---

## ğŸ”§ Implementation Details

### **File structure:**
```python
models/
â”œâ”€â”€ cl_strategies.py          # â† All strategies
â”‚   â”œâ”€â”€ BaselineStrategy
â”‚   â”œâ”€â”€ SEMAStrategy
â”‚   â”œâ”€â”€ MemoryExpansionStrategy
â”‚   â””â”€â”€ SEMAMemExpandStrategy
â”œâ”€â”€ uniad_learner.py           # Uses strategies
â””â”€â”€ ...
```

### **Core methods:**
```python
class CLStrategy:
    def after_task(network, task_id):
        # Freeze modules sau task
        pass
    
    def before_task(network, task_id):
        # Setup trÆ°á»›c task má»›i
        pass
```

### **Memory Expansion forward:**
```python
# MemExpand inference
outputs = []

# Forward qua frozen modules
for task_module in frozen_modules:
    with torch.no_grad():
        out = task_module(input)
        outputs.append(out)

# Forward qua current module
out_current = current_module(input)
outputs.append(out_current)

# Mix outputs
final_pred = average(outputs)
```

---

## ğŸ“ References

1. **SEMA** (CVPR 2025): Self-Expansion with Mixture of Adapters
2. **MemExpand**: Inspired by Progressive Neural Networks
3. **AnoCL**: Continual Learning for Anomaly Detection

---

**Chá»n strategy phÃ¹ há»£p vá»›i requirements cá»§a báº¡n! ğŸš€**
